{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "import shutil\n",
    "import rasterio\n",
    "import shapefile\n",
    "from shapely.geometry import shape, Polygon, MultiPolygon\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_structure(output_folder):\n",
    "    \"\"\"Create the dataset directory structure\"\"\"\n",
    "    splits = ['train', 'val', 'test']\n",
    "    types = ['images', 'labels']\n",
    "    \n",
    "    for type_dir in types:\n",
    "        for split in splits:\n",
    "            path = Path(output_folder) / 'segment' / type_dir / split\n",
    "            path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create the YAML configuration file for the dataset\n",
    "    yaml_content = {\n",
    "        'path': '',\n",
    "        'train': 'images/train',\n",
    "        'val': 'images/val',\n",
    "        'test': 'images/test',\n",
    "        'names': {\n",
    "            0: 'warm_roof',\n",
    "            1: 'cool_roof'\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    yaml_path = Path(output_folder) / 'segment' / 'segment.yaml'\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        yaml.safe_dump(yaml_content, f, sort_keys=False)\n",
    "\n",
    "    return splits\n",
    "\n",
    "def assign_split(splits, split_ratios):\n",
    "    \"\"\"Assign a split based on the provided ratios\"\"\"\n",
    "    rand_val = random.random()\n",
    "    cumulative = 0\n",
    "    for split, ratio in zip(splits, split_ratios):\n",
    "        cumulative += ratio\n",
    "        if rand_val <= cumulative:\n",
    "            return split\n",
    "    return splits[-1]  # Fallback to last split\n",
    "\n",
    "def coords_to_pixel(x, y, transform, img_width, img_height):\n",
    "    \"\"\"Convert coordinates to pixel row and column with bounds checking\"\"\"\n",
    "    col, row = ~transform * (x, y)\n",
    "    \n",
    "    # Normalize and clamp coordinates to [0,1]\n",
    "    col = max(0, min(1, col / img_width))\n",
    "    row = max(0, min(1, row / img_height))\n",
    "\n",
    "    return col, row\n",
    "\n",
    "def validate_polygon(points, img_width, img_height):\n",
    "    \"\"\"\n",
    "    Validate polygon coordinates and ensure they are within image boundaries\n",
    "    Returns: (is_valid, message)\n",
    "    \"\"\"\n",
    "    if not points or len(points) < 3:  # Need at least 3 points for a polygon\n",
    "        return False, \"Too few points for polygon\"\n",
    "    \n",
    "    # Check if all coordinates are within [0,1] range\n",
    "    for x, y in points:\n",
    "        if not (0 <= x <= 1 and 0 <= y <= 1):\n",
    "            return False, f\"Coordinates out of bounds: ({x}, {y})\"\n",
    "    \n",
    "    # Check if polygon has non-zero area\n",
    "    # Convert normalized coordinates back to pixels for area calculation\n",
    "    pixel_points = [(x * img_width, y * img_height) for x, y in points]\n",
    "    polygon = Polygon(pixel_points)\n",
    "    if polygon.area < 1:  # Area less than 1 pixel\n",
    "        return False, \"Polygon area too small\"\n",
    "        \n",
    "    return True, \"Valid polygon\"\n",
    "\n",
    "def process_geometry(geom, transform, img_width, img_height):\n",
    "    \"\"\"\n",
    "    Process a geometry (Polygon or MultiPolygon) and return list of valid coordinate strings\n",
    "    \"\"\"\n",
    "    valid_polygons = []\n",
    "    \n",
    "    if isinstance(geom, MultiPolygon):\n",
    "        # Process each part of the MultiPolygon separately\n",
    "        for part in geom.geoms:\n",
    "            if isinstance(part, Polygon):\n",
    "                points = list(part.exterior.coords)\n",
    "                pixel_points = [coords_to_pixel(x, y, transform, img_width, img_height) \n",
    "                              for x, y in points]\n",
    "                \n",
    "                is_valid, message = validate_polygon(pixel_points, img_width, img_height)\n",
    "                if is_valid:\n",
    "                    coord_str = ' '.join(f\"{x} {y}\" for x, y in pixel_points)\n",
    "                    valid_polygons.append(coord_str)\n",
    "    \n",
    "    elif isinstance(geom, Polygon):\n",
    "        points = list(geom.exterior.coords)\n",
    "        pixel_points = [coords_to_pixel(x, y, transform, img_width, img_height) \n",
    "                       for x, y in points]\n",
    "        \n",
    "        is_valid, message = validate_polygon(pixel_points, img_width, img_height)\n",
    "        if is_valid:\n",
    "            coord_str = ' '.join(f\"{x} {y}\" for x, y in pixel_points)\n",
    "            valid_polygons.append(coord_str)\n",
    "    \n",
    "    return valid_polygons\n",
    "\n",
    "def create_dataset(image_folder, shapefile_folder, output_folder, split_ratios=(0.7, 0.2, 0.1)):\n",
    "    \"\"\"\n",
    "    Create a custom dataset by converting shapefiles to YOLO segmentation format using 'cool_roof'\n",
    "    field as class_id and split into train/val/test sets\n",
    "    \"\"\"\n",
    "    # Validate split ratios\n",
    "    if len(split_ratios) != 3 or abs(sum(split_ratios) - 1.0) > 1e-9:\n",
    "        raise ValueError(\"Split ratios must be a tuple of 3 numbers that sum to 1.0\")\n",
    "    \n",
    "    # Set random seed for reproducibility\n",
    "    random.seed(42)\n",
    "    \n",
    "    # Create dataset directory structure\n",
    "    splits = create_dataset_structure(output_folder)\n",
    "    \n",
    "    # Convert paths to Path objects\n",
    "    image_folder = Path(image_folder)\n",
    "    shapefile_folder = Path(shapefile_folder)\n",
    "    output_folder = Path(output_folder)\n",
    "    \n",
    "    # Track statistics\n",
    "    stats = {\n",
    "        'processed': 0,\n",
    "        'skipped': 0,\n",
    "        'invalid_polygons': 0,\n",
    "        'empty_labels': 0,\n",
    "        'multipart_processed': 0\n",
    "    }\n",
    "\n",
    "    # Process each shapefile\n",
    "    shp_files = list(shapefile_folder.glob(\"*.shp\"))\n",
    "    for shp_file in shp_files:        \n",
    "        # Use shapefile name to find corresponding image\n",
    "        base_name = shp_file.stem\n",
    "        \n",
    "        # Search recursively through image_folder and its subdirectories\n",
    "        matching_images = list(image_folder.rglob(f\"{base_name}.jpg\"))\n",
    "        \n",
    "        if not matching_images:\n",
    "            print(f\"Warning: No matching image for {shp_file}\")\n",
    "            continue\n",
    "        \n",
    "        # Use the first matching image if multiple are found\n",
    "        if len(matching_images) > 1:\n",
    "            print(f\"Warning: Multiple matching images found for {shp_file}. Using {matching_images[0]}\")\n",
    "        \n",
    "        img_path = matching_images[0]\n",
    "        \n",
    "        with rasterio.open(img_path) as src:\n",
    "            width, height = src.width, src.height\n",
    "            transform = src.transform\n",
    "\n",
    "        # Assign to a split\n",
    "        split = assign_split(splits, split_ratios)\n",
    "        \n",
    "        # Define paths for label and image in new structure\n",
    "        label_path = output_folder / 'segment' / 'labels' / split / f\"{base_name}.txt\"\n",
    "        new_img_path = output_folder / 'segment' / 'images' / split / f\"{base_name}.jpg\"\n",
    "        \n",
    "        sf = shapefile.Reader(shp_file)\n",
    "        valid_polygons = False  # Track if file has any valid polygons\n",
    "\n",
    "        # Create temporary label file\n",
    "        temp_label_path = label_path.with_suffix('.tmp')\n",
    "\n",
    "        # Write label file\n",
    "        with open(temp_label_path, 'w') as f:\n",
    "            for shape_record in sf.shapeRecords():\n",
    "                label = int(shape_record.record['cool_roof']) # Assuming the label is stored in the attribute table\n",
    "                geom = shape(shape_record.shape.__geo_interface__)\n",
    "                \n",
    "                # Process the geometry and get valid coordinate strings\n",
    "                valid_coord_strings = process_geometry(geom, transform, width, height)\n",
    "                \n",
    "                # Write valid polygons to file\n",
    "                for coord_str in valid_coord_strings:\n",
    "                    valid_polygons = True\n",
    "                    f.write(f\"{label} {coord_str}/n\")\n",
    "                    \n",
    "                if isinstance(geom, MultiPolygon) and valid_coord_strings:\n",
    "                    stats['multipart_processed'] += 1\n",
    "        \n",
    "        # Only keep files with valid polygons\n",
    "        if valid_polygons:\n",
    "            temp_label_path.rename(label_path)\n",
    "            shutil.copy2(img_path, new_img_path)\n",
    "            stats['processed'] += 1\n",
    "            print(f\"Processed {base_name} -> {split}\")\n",
    "        else:\n",
    "            temp_label_path.unlink(missing_ok=True)\n",
    "            stats['empty_labels'] += 1\n",
    "            print(f\"Skipping {base_name}: No valid polygons\")\n",
    "    \n",
    "    # Print distribution and statistics summary\n",
    "    print(\"\\nDataset Distribution:\")\n",
    "    for split in splits:\n",
    "        label_files = list((output_folder / 'segment' / 'labels' / split).glob('*.txt'))\n",
    "        image_files = list((output_folder / 'segment' / 'images' / split).glob('*.jpg'))\n",
    "        print(f\"{split}: {len(label_files)} labels, {len(image_files)} images\")\n",
    "    \n",
    "    print(\"\\nProcessing Statistics:\")\n",
    "    print(f\"Successfully processed: {stats['processed']} files\")\n",
    "    print(f\"Skipped (no matching image): {stats['skipped']} files\")\n",
    "    print(f\"Invalid polygons encountered: {stats['invalid_polygons']}\")\n",
    "    print(f\"Files with no valid polygons: {stats['empty_labels']}\")\n",
    "    print(f\"Multipart polygons successfully processed: {stats['multipart_processed']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed NYCortho2022_1011 -> train\n",
      "Processed NYCortho2022_1012 -> train\n",
      "Processed NYCortho2022_1033 -> train\n",
      "Processed NYCortho2022_1040 -> train\n",
      "Processed NYCortho2022_1046 -> val\n",
      "Processed NYCortho2022_1053 -> train\n",
      "Processed NYCortho2022_1055 -> val\n",
      "Processed NYCortho2022_1057 -> train\n",
      "Processed NYCortho2022_1062 -> train\n",
      "Processed NYCortho2022_1064 -> train\n",
      "Processed NYCortho2022_1073 -> train\n",
      "Processed NYCortho2022_1078 -> train\n",
      "Processed NYCortho2022_1100 -> train\n",
      "Processed NYCortho2022_1127 -> train\n",
      "Processed NYCortho2022_1182 -> train\n",
      "Processed NYCortho2022_1187 -> train\n",
      "Processed NYCortho2022_1224 -> train\n",
      "Processed NYCortho2022_1226 -> train\n",
      "Processed NYCortho2022_1233 -> val\n",
      "Processed NYCortho2022_1236 -> train\n",
      "Processed NYCortho2022_1256 -> val\n",
      "Processed NYCortho2022_1257 -> train\n",
      "Processed NYCortho2022_1264 -> train\n",
      "Processed NYCortho2022_1296 -> train\n",
      "Processed NYCortho2022_1298 -> test\n",
      "Processed NYCortho2022_1301 -> train\n",
      "Processed NYCortho2022_133 -> train\n",
      "Processed NYCortho2022_1357 -> train\n",
      "Processed NYCortho2022_1374 -> val\n",
      "Processed NYCortho2022_1442 -> train\n",
      "Processed NYCortho2022_1463 -> val\n",
      "Processed NYCortho2022_1506 -> val\n",
      "Processed NYCortho2022_1509 -> train\n",
      "Processed NYCortho2022_1510 -> test\n",
      "Processed NYCortho2022_1514 -> train\n",
      "Processed NYCortho2022_1516 -> train\n",
      "Processed NYCortho2022_1521 -> val\n",
      "Processed NYCortho2022_1523 -> train\n",
      "Processed NYCortho2022_1565 -> val\n",
      "Processed NYCortho2022_1570 -> train\n",
      "Processed NYCortho2022_1589 -> val\n",
      "Processed NYCortho2022_1593 -> train\n",
      "Processed NYCortho2022_1630 -> train\n",
      "Processed NYCortho2022_1636 -> train\n",
      "Processed NYCortho2022_1650 -> train\n",
      "Processed NYCortho2022_1655 -> train\n",
      "Processed NYCortho2022_1692 -> train\n",
      "Processed NYCortho2022_1697 -> train\n",
      "Processed NYCortho2022_1708 -> train\n",
      "Processed NYCortho2022_1715 -> train\n",
      "Processed NYCortho2022_1719 -> train\n",
      "Processed NYCortho2022_1755 -> train\n",
      "Processed NYCortho2022_1756 -> train\n",
      "Processed NYCortho2022_1768 -> test\n",
      "Processed NYCortho2022_1772 -> train\n",
      "Processed NYCortho2022_1774 -> train\n",
      "Processed NYCortho2022_1775 -> train\n",
      "Processed NYCortho2022_1816 -> val\n",
      "Processed NYCortho2022_1824 -> train\n",
      "Processed NYCortho2022_1826 -> train\n",
      "Processed NYCortho2022_1833 -> test\n",
      "Processed NYCortho2022_1836 -> train\n",
      "Processed NYCortho2022_1839 -> train\n",
      "Processed NYCortho2022_1841 -> train\n",
      "Processed NYCortho2022_1843 -> val\n",
      "Processed NYCortho2022_1844 -> val\n",
      "Processed NYCortho2022_1894 -> train\n",
      "Processed NYCortho2022_1898 -> train\n",
      "Processed NYCortho2022_1947 -> train\n",
      "Processed NYCortho2022_1960 -> train\n",
      "Processed NYCortho2022_1964 -> train\n",
      "Processed NYCortho2022_1971 -> test\n",
      "Processed NYCortho2022_1972 -> val\n",
      "Processed NYCortho2022_1975 -> train\n",
      "Processed NYCortho2022_200 -> train\n",
      "Processed NYCortho2022_2014 -> train\n",
      "Processed NYCortho2022_2026 -> test\n",
      "Processed NYCortho2022_2033 -> train\n",
      "Processed NYCortho2022_2080 -> train\n",
      "Processed NYCortho2022_2083 -> train\n",
      "Processed NYCortho2022_2087 -> train\n",
      "Processed NYCortho2022_2105 -> train\n",
      "Processed NYCortho2022_2140 -> train\n",
      "Processed NYCortho2022_2142 -> val\n",
      "Processed NYCortho2022_2143 -> train\n",
      "Processed NYCortho2022_2156 -> train\n",
      "Processed NYCortho2022_2164 -> test\n",
      "Processed NYCortho2022_2205 -> train\n",
      "Processed NYCortho2022_2210 -> train\n",
      "Processed NYCortho2022_2214 -> train\n",
      "Processed NYCortho2022_2215 -> train\n",
      "Processed NYCortho2022_2217 -> train\n",
      "Processed NYCortho2022_2235 -> val\n",
      "Processed NYCortho2022_2236 -> train\n",
      "Processed NYCortho2022_2270 -> train\n",
      "Processed NYCortho2022_2278 -> train\n",
      "Processed NYCortho2022_2295 -> test\n",
      "Processed NYCortho2022_2296 -> train\n",
      "Processed NYCortho2022_2298 -> test\n",
      "Processed NYCortho2022_2336 -> val\n",
      "Processed NYCortho2022_2337 -> train\n",
      "Processed NYCortho2022_2341 -> val\n",
      "Processed NYCortho2022_2352 -> train\n",
      "Processed NYCortho2022_2361 -> train\n",
      "Processed NYCortho2022_2364 -> train\n",
      "Processed NYCortho2022_2399 -> train\n",
      "Processed NYCortho2022_2415 -> train\n",
      "Processed NYCortho2022_2421 -> train\n",
      "Processed NYCortho2022_2422 -> train\n",
      "Processed NYCortho2022_2468 -> test\n",
      "Processed NYCortho2022_2470 -> val\n",
      "Processed NYCortho2022_2487 -> train\n",
      "Processed NYCortho2022_2490 -> train\n",
      "Processed NYCortho2022_2551 -> train\n",
      "Processed NYCortho2022_259 -> test\n",
      "Processed NYCortho2022_2607 -> val\n",
      "Processed NYCortho2022_2608 -> train\n",
      "Processed NYCortho2022_2614 -> train\n",
      "Processed NYCortho2022_2616 -> train\n",
      "Processed NYCortho2022_263 -> train\n",
      "Processed NYCortho2022_2657 -> val\n",
      "Processed NYCortho2022_266 -> train\n",
      "Processed NYCortho2022_2661 -> val\n",
      "Processed NYCortho2022_2663 -> train\n",
      "Processed NYCortho2022_2672 -> train\n",
      "Processed NYCortho2022_2680 -> train\n",
      "Processed NYCortho2022_2719 -> train\n",
      "Processed NYCortho2022_2721 -> test\n",
      "Processed NYCortho2022_2729 -> val\n",
      "Processed NYCortho2022_2733 -> val\n",
      "Processed NYCortho2022_2785 -> train\n",
      "Processed NYCortho2022_2787 -> train\n",
      "Processed NYCortho2022_2788 -> val\n",
      "Processed NYCortho2022_2790 -> test\n",
      "Processed NYCortho2022_2794 -> train\n",
      "Processed NYCortho2022_2803 -> train\n",
      "Processed NYCortho2022_2804 -> train\n",
      "Processed NYCortho2022_2805 -> val\n",
      "Processed NYCortho2022_2850 -> val\n",
      "Processed NYCortho2022_2859 -> train\n",
      "Processed NYCortho2022_2865 -> train\n",
      "Processed NYCortho2022_2930 -> train\n",
      "Processed NYCortho2022_2978 -> train\n",
      "Processed NYCortho2022_2981 -> val\n",
      "Processed NYCortho2022_2987 -> train\n",
      "Processed NYCortho2022_2990 -> train\n",
      "Processed NYCortho2022_2992 -> train\n",
      "Processed NYCortho2022_3042 -> val\n",
      "Processed NYCortho2022_3045 -> train\n",
      "Processed NYCortho2022_3046 -> train\n",
      "Processed NYCortho2022_3052 -> test\n",
      "Processed NYCortho2022_3057 -> train\n",
      "Processed NYCortho2022_3107 -> train\n",
      "Processed NYCortho2022_3116 -> train\n",
      "Processed NYCortho2022_3178 -> train\n",
      "Processed NYCortho2022_3183 -> train\n",
      "Processed NYCortho2022_323 -> train\n",
      "Processed NYCortho2022_3236 -> train\n",
      "Processed NYCortho2022_3238 -> train\n",
      "Processed NYCortho2022_325 -> train\n",
      "Processed NYCortho2022_3252 -> train\n",
      "Processed NYCortho2022_326 -> train\n",
      "Processed NYCortho2022_3300 -> train\n",
      "Processed NYCortho2022_3305 -> test\n",
      "Processed NYCortho2022_3312 -> val\n",
      "Processed NYCortho2022_3367 -> train\n",
      "Processed NYCortho2022_3382 -> train\n",
      "Processed NYCortho2022_3431 -> train\n",
      "Processed NYCortho2022_3434 -> train\n",
      "Processed NYCortho2022_3494 -> train\n",
      "Processed NYCortho2022_3499 -> test\n",
      "Processed NYCortho2022_3503 -> train\n",
      "Processed NYCortho2022_3509 -> train\n",
      "Processed NYCortho2022_3626 -> val\n",
      "Processed NYCortho2022_3631 -> val\n",
      "Processed NYCortho2022_3632 -> train\n",
      "Processed NYCortho2022_3692 -> train\n",
      "Processed NYCortho2022_3751 -> train\n",
      "Processed NYCortho2022_387 -> train\n",
      "Processed NYCortho2022_391 -> train\n",
      "Processed NYCortho2022_396 -> val\n",
      "Processed NYCortho2022_398 -> train\n",
      "Processed NYCortho2022_455 -> test\n",
      "Processed NYCortho2022_456 -> train\n",
      "Processed NYCortho2022_464 -> train\n",
      "Processed NYCortho2022_517 -> train\n",
      "Processed NYCortho2022_520 -> val\n",
      "Processed NYCortho2022_525 -> train\n",
      "Processed NYCortho2022_526 -> train\n",
      "Processed NYCortho2022_527 -> train\n",
      "Processed NYCortho2022_528 -> train\n",
      "Processed NYCortho2022_529 -> train\n",
      "Processed NYCortho2022_593 -> train\n",
      "Processed NYCortho2022_657 -> test\n",
      "Processed NYCortho2022_67 -> train\n",
      "Processed NYCortho2022_679 -> val\n",
      "Processed NYCortho2022_68 -> train\n",
      "Processed NYCortho2022_682 -> train\n",
      "Processed NYCortho2022_69 -> test\n",
      "Processed NYCortho2022_720 -> val\n",
      "Processed NYCortho2022_776 -> test\n",
      "Processed NYCortho2022_786 -> test\n",
      "Processed NYCortho2022_800 -> val\n",
      "Processed NYCortho2022_844 -> train\n",
      "Processed NYCortho2022_846 -> train\n",
      "Processed NYCortho2022_847 -> train\n",
      "Processed NYCortho2022_853 -> train\n",
      "Processed NYCortho2022_863 -> train\n",
      "Processed NYCortho2022_874 -> train\n",
      "Processed NYCortho2022_879 -> test\n",
      "Processed NYCortho2022_913 -> train\n",
      "Processed NYCortho2022_929 -> val\n",
      "Processed NYCortho2022_933 -> train\n",
      "Processed NYCortho2022_935 -> train\n",
      "Processed NYCortho2022_937 -> test\n",
      "Processed NYCortho2022_950 -> test\n",
      "Processed NYCortho2022_980 -> train\n",
      "Processed NYCortho2022_993 -> val\n",
      "Processed NYCortho2022_995 -> train\n",
      "Processed NYCortho2022_997 -> train\n",
      "\n",
      "Dataset Distribution:\n",
      "train: 157 labels, 157 images\n",
      "val: 39 labels, 39 images\n",
      "test: 24 labels, 24 images\n",
      "\n",
      "Processing Statistics:\n",
      "Successfully processed: 220 files\n",
      "Skipped (no matching image): 0 files\n",
      "Invalid polygons encountered: 0\n",
      "Files with no valid polygons: 0\n",
      "Multipart polygons successfully processed: 85\n"
     ]
    }
   ],
   "source": [
    "image_folder = \"C:/Users/jdhoc/Desktop/DOT Volunteer Project/data/raster/output/NYC_ortho_2022/jpg\"\n",
    "shapefile_folder = \"C:/Users/jdhoc/Desktop/DOT Volunteer Project/data/vector/processed/NYCortho22/filteredBldgs_randSub1\"\n",
    "output_folder = \"C:/Users/jdhoc/Desktop/DOT Volunteer Project/data/labels/cool-roofs_filteredBldgs_randSub1\"\n",
    "\n",
    "# Custom split ratios (must sum to 1.0)\n",
    "split_ratios = (0.7, 0.2, 0.1)  # train, val, test\n",
    "\n",
    "create_dataset(image_folder, shapefile_folder, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
